{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/page-jerzak/ai_computing/blob/main/DSMDLP_Module3_Part1_Prediction_Modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Challenge: K-Fold Cross Validation\n",
        "Using this code, revise the Logistic Regression training procedure to instead apply a 10-fold cross validation. You will be using the same dataset as the previous assignment, and an abbreviate preprocessing pipeline has been provided.\n",
        "\n",
        "For this assignment, our goal is to train a model to predict whether students are likely to complete their next math assignment."
      ],
      "metadata": {
        "id": "tTmSUN8xbZVA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "\n",
        "This assignment will utilize student data collected from the ASSISTments digital learning platform. The dataset contains data from 18,345 unique students across 37,268 assignments. For each of these, our goal is to predict whether each student will complete the assignment using their past performance and behavior in the system. Several student level features have been aggregated for each student up to the moment that they were given the target assignment, and we want to examine whether this information can be used to predict their future performance (as measured by completion of the next assignment).\n",
        "\n",
        "**The dataset can be downloaded from Canvas or using this direct link:\n",
        "[ASSISTments Assignments Dataset](https://drive.google.com/file/d/1oEEKSkDPn8RBM6oa9eNmXYIFBmxqFQBm/view?usp=sharing)**\n",
        "\n",
        "The dataset used in this assignment has been sampled from a larger publicly-available dataset published in the International Conference on Educational Data Mining:\n",
        "\n",
        "[Prihar, E., Syed, M., Ostrow, K., Shaw, S., Sales, A., & Heffernan, N. (2022, July). Exploring common trends in online educational experiments. *In Proceedings of the 15th International Conference on Educational Data Mining.*](https://educationaldatamining.org/edm2022/proceedings/2022.EDM-long-papers.3/index.html)\n",
        "\n",
        "**A description of each column and further context for the data can be found in that paper.**"
      ],
      "metadata": {
        "id": "2LCsq4SUVc2Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Loading and Preprocessing\n",
        "Download the **assistments_control_assignments_with_priors.csv** file from Canvas or the link above. Run the first code cell below to upload the dataset. The second code cell below uses the pandas library to read the file into a Dataframe and displays the number of rows and columns as well as a sample of the loaded data.\n",
        "\n"
      ],
      "metadata": {
        "id": "tv3v15DIceLI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25P0zowFbY7w"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "dataset = files.upload()\n",
        "filename = list(dataset.keys())[0]\n",
        "print(f\"{filename} has been uploaded\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(filename)\n",
        "\n",
        "# Drop rows with missing values\n",
        "df = df.dropna()\n",
        "\n",
        "# Print the shape of the dataset\n",
        "print(\"\\nShape of the dataset (rows, columns):\", df.shape)\n",
        "\n",
        "# Display a sample of the dataset\n",
        "df\n"
      ],
      "metadata": {
        "id": "aVopuYusdOXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Descriptive Statistics\n",
        "\n",
        "Following the previous assignment, the code below identifies all the features that were considered in the previous assignment in addition to a set of features for which there is low correlation. Feel free to replace these features with the set that you identified in the previous assignment."
      ],
      "metadata": {
        "id": "s49nEEF8QQ7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The list of all potential features we can utilize\n",
        "# Note: class- and teacher-level variables are omitted for this assignment,\n",
        "#       but these may be useful in other contexts\n",
        "all_features = ['0_student_prior_skill_builders',\n",
        "                      '0_student_prior_problem_sets',\n",
        "                      '0_student_prior_attempted_problems',\n",
        "                      '0_student_prior_completed_problems',\n",
        "                      'student_prior_started_skill_builder_count',\n",
        "                      'student_prior_skill_builder_percent_completed',\n",
        "                      'student_prior_started_problem_set_count',\n",
        "                      'student_prior_problem_set_percent_completed',\n",
        "                      'student_prior_completed_problem_count',\n",
        "                      'student_prior_median_first_response_time',\n",
        "                      'student_prior_median_time_on_task',\n",
        "                      'student_prior_average_attempt_count',\n",
        "                      'student_prior_average_correctness',\n",
        "                      'opportunity_zone']\n",
        "\n",
        "# The following represents one possible permutation of features\n",
        "low_corr_features = ['0_student_prior_completed_problems',\n",
        "                      'student_prior_started_skill_builder_count',\n",
        "                      'student_prior_skill_builder_percent_completed',\n",
        "                      'student_prior_problem_set_percent_completed',\n",
        "                      'student_prior_completed_problem_count',\n",
        "                      'student_prior_median_first_response_time',\n",
        "                      'student_prior_average_attempt_count',\n",
        "                      'student_prior_average_correctness',\n",
        "                      'opportunity_zone']\n",
        "\n",
        "dependent_variable = \"assignment_completed\"\n",
        "df_features = df[all_features]\n",
        "\n",
        "# Display the means and standard deviations\n",
        "stats = {}\n",
        "stats['Mean'] = df_features.mean(numeric_only=True)\n",
        "stats['SD'] = df_features.std(numeric_only=True)\n",
        "\n",
        "feature_statistics = pd.DataFrame(stats)\n",
        "\n",
        "print(f\"The dataset contains a total of {len(df)} rows and {len(df.columns)} columns\")\n",
        "print(f\"{len(all_features)} potential feature columns have been identified:\")\n",
        "print(feature_statistics.round(2))\n",
        "print(\"==========\")\n",
        "print(f\"Dependent Measure: {dependent_variable}\")\n",
        "print(f\"{round(df[dependent_variable].mean()*100,2)}% of the {df[dependent_variable].sum()} total assignments were completed\")"
      ],
      "metadata": {
        "id": "UFBRgHUFPNuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Logistic Regression\n",
        "\n",
        "With our set of selected features your goal is to modify the code below to instead implement a K-fold cross validation. Refer to the ASSISTments assignment for hints as to how to get started if you are unsure."
      ],
      "metadata": {
        "id": "CsdWNhUWdXpA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, cohen_kappa_score, roc_auc_score\n",
        "\n",
        "\n",
        "# Create variables for our dependent variable and the set of selected features\n",
        "X = df[selected_features]\n",
        "y = df[dependent_variable]\n",
        "\n",
        "# Split our data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Fit and train the logistic regression model with sklearn\n",
        "lr_model = LogisticRegression()\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions using sklearn model\n",
        "y_pred_sklearn = lr_model.predict(X_test)\n",
        "y_pred_proba_sklearn = lr_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Model performance metrics using sklearn predictions\n",
        "accuracy = accuracy_score(y_test, y_pred_sklearn)\n",
        "kappa = cohen_kappa_score(y_test, y_pred_sklearn)\n",
        "auc = roc_auc_score(y_test, y_pred_proba_sklearn)\n",
        "\n",
        "# Create a DataFrame to store performance metrics\n",
        "performance = pd.DataFrame({'Metric': ['Accuracy', 'Kappa', 'AUC'], 'Value': [accuracy, kappa, auc]})\n",
        "\n",
        "# Display performance metrics and regression coefficients\n",
        "print(\"Performance Metrics using scikit-learn:\")\n",
        "print(performance)\n"
      ],
      "metadata": {
        "id": "l4HWDnuVedRf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}